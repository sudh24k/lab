{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P68iuOqO1lCH",
        "outputId": "fa929b24-4594-4c1e-c87a-65e1a02d66f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m573.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.25.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
            "Installing collected packages: keras_preprocessing\n",
            "Successfully installed keras_preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ausn95ugzVDC"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's load the dataset and then split\n",
        "# it into training and testing sets\n",
        "features = 2000\n",
        "len = 50\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=features)\n",
        "\n",
        "\n",
        "# we are using pad sequences to a fixed length\n",
        "X_train = pad_sequences(X_train, maxlen=len)\n",
        "X_test = pad_sequences(X_test, maxlen=len)"
      ],
      "metadata": {
        "id": "sL5A2zAO1sFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afcbbced-b22c-4bfa-b63d-397d68aa4101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SWNjr2c5-h9",
        "outputId": "502b1892-f9e0-4b6a-bf68-ba79b99dc286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000, 50)\n",
            "(25000, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XC3StOQw6oI3",
        "outputId": "0f24269d-ef78-48c9-a2f7-8d2a2f40d974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7okb2zX86teQ",
        "outputId": "676247d6-0080-42cc-872d-7953c92fefa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1FVy3v56Kmd",
        "outputId": "17720f0c-4f1a-4088-9858-2c7760f390f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,    5,    2,  656,  245,    2,    5,    4,    2,  131,  152,\n",
              "        491,   18,    2,   32,    2, 1212,   14,    9,    6,  371,   78,\n",
              "         22,  625,   64, 1382,    9,    8,  168,  145,   23,    4, 1690,\n",
              "         15,   16,    4, 1355,    5,   28,    6,   52,  154,  462,   33,\n",
              "         89,   78,  285,   16,  145,   95], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting all the words from word_index dictionary\n",
        "word_idx = imdb.get_word_index()\n",
        "\n",
        "# Originally the index number of a value and not a key,\n",
        "# hence converting the index as key and the words as values\n",
        "word_idx = {i: word for word, i in word_idx.items()}\n",
        "\n",
        "# again printing the review\n",
        "print([word_idx[i] for i in X_train[1]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pk2eIm__8DU",
        "outputId": "2c5dec22-3512-4e15-dcb5-0aa055195faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and', 'to', 'and', 'finds', 'tv', 'and', 'to', 'of', 'and', 'these', 'thing', 'wants', 'but', 'and', 'an', 'and', 'cult', 'as', 'it', 'is', 'video', 'do', 'you', 'david', 'see', 'scenery', 'it', 'in', 'few', 'those', 'are', 'of', 'ship', 'for', 'with', 'of', 'wild', 'to', 'one', 'is', 'very', 'work', 'dark', 'they', \"don't\", 'do', 'dvd', 'with', 'those', 'them']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,Bidirectional, SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "X1-6Q4sA2JOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unidirectional RNN**"
      ],
      "metadata": {
        "id": "k5XEhDY936cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the values for the embedding size and\n",
        "# number of hidden units in the RNN layer\n",
        "embedding = 128\n",
        "hidden = 64\n",
        "\n",
        "# Create a Sequential model object\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(features, embedding,\n",
        "                    input_length=len))\n",
        "model1.add(SimpleRNN(hidden))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "model1.compile('adam', 'binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "print(model1.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eexwcKtW34xN",
        "outputId": "44866b94-fed1-42a5-b0fc-994f6f0e4b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 50, 128)           256000    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 64)                12352     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 268417 (1.02 MB)\n",
            "Trainable params: 268417 (1.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set batch size and number of epochs you want\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "model1.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX6W8pfe4EAt",
        "outputId": "9e4e6da4-f747-4681-97a7-99e8aaddca1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.1325 - accuracy: 0.9510 - val_loss: 0.8017 - val_accuracy: 0.7646\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 41s 52ms/step - loss: 0.1019 - accuracy: 0.9618 - val_loss: 0.8783 - val_accuracy: 0.7547\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.0787 - accuracy: 0.9706 - val_loss: 1.0735 - val_accuracy: 0.7478\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 40s 52ms/step - loss: 0.0778 - accuracy: 0.9714 - val_loss: 1.1607 - val_accuracy: 0.6940\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.0609 - accuracy: 0.9792 - val_loss: 1.1808 - val_accuracy: 0.7277\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa13afca470>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# redefine model to output right after the first hidden layer\n",
        "from tensorflow.keras.models import Model\n",
        "model = Model(inputs=model1.inputs, outputs=model1.layers[0].output)"
      ],
      "metadata": {
        "id": "vHxy_aCUfvZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = model.predict(X_test[1])\n",
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shIcDNCqgAA1",
        "outputId": "711037a4-276e-4f9d-de6d-5007f4ac9ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00106409,  0.00824866, -0.06177601, ...,  0.07349478,\n",
              "        -0.00321336,  0.0601719 ],\n",
              "       [ 0.06690077,  0.1407671 ,  0.11387948, ..., -0.07172091,\n",
              "        -0.01006031,  0.06057109],\n",
              "       [ 0.06584854,  0.05550298,  0.10783064, ..., -0.07560354,\n",
              "        -0.16340974, -0.04044654],\n",
              "       ...,\n",
              "       [ 0.11216965, -0.02822897,  0.03434373, ...,  0.16575745,\n",
              "        -0.04417638, -0.10910487],\n",
              "       [-0.01357045, -0.06024994,  0.02101284, ...,  0.06257634,\n",
              "         0.03904661, -0.04472475],\n",
              "       [-0.03808314,  0.00602651, -0.03074027, ..., -0.00720564,\n",
              "         0.03058059,  0.03611491]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptpmGNhpgLqN",
        "outputId": "a870044d-ea10-417b-d9ef-05d6db5c0dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modell = Model(inputs=model1.inputs, outputs=model1.layers[1].output)\n",
        "\n",
        "from numpy import expand_dims\n",
        "test = expand_dims(X_test[1], axis=0)\n",
        "features1 = modell.predict(test)\n",
        "features1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adlfHVaVga01",
        "outputId": "845f909b-e8a1-4986-d459-4ee6500fb268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNzcpaJLm1kq",
        "outputId": "d9a328b0-14a2-4941-f491-bcf912de2666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.32096925,  0.30421415, -0.51208115, -0.12544009,  0.35478204,\n",
              "         0.77132887, -0.6182165 ,  0.5002717 ,  0.5565328 ,  0.644142  ,\n",
              "        -0.53504133,  0.24685372,  0.3491055 ,  0.5667802 , -0.39225712,\n",
              "        -0.7219206 ,  0.24904081,  0.7040414 ,  0.09419011, -0.00671036,\n",
              "        -0.4555903 , -0.01029287, -0.6439581 , -0.38241813,  0.46459112,\n",
              "        -0.07471412, -0.5883243 ,  0.10084566,  0.07496008,  0.41974232,\n",
              "        -0.45979035, -0.3968719 ,  0.49346355,  0.03045777,  0.2893414 ,\n",
              "         0.7763445 ,  0.5831679 , -0.14925617,  0.84397584, -0.09846085,\n",
              "        -0.21466005,  0.16398564,  0.11852946,  0.8432917 , -0.59958535,\n",
              "         0.38087532,  0.55744755,  0.6256532 ,  0.62337977, -0.5187323 ,\n",
              "         0.3822637 ,  0.22667266,  0.58393705, -0.4100626 , -0.78901213,\n",
              "         0.14078994, -0.60938674,  0.0809363 ,  0.20822577,  0.2514704 ,\n",
              "        -0.17318065,  0.43036172,  0.56032586, -0.0779899 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "\n",
        "loss, accuracy = model1.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Ad568L4sB9",
        "outputId": "f8ec507a-91b5-4160-d976-0ec11ef46ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 5s 7ms/step - loss: 0.6882 - accuracy: 0.7387\n",
            "Test accuracy: 0.7387199997901917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bidirectional RNN**"
      ],
      "metadata": {
        "id": "jGyy1zJT4x5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the values for the embedding size and\n",
        "# number of hidden units in the RNN layer\n",
        "embedding = 128\n",
        "hidden = 64\n",
        "\n",
        "# Create a Sequential model object\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(features, embedding,\n",
        "                    input_length=len))\n",
        "model2.add(Bidirectional(SimpleRNN(hidden)))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile('adam', 'binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGb8YCY_2Qju",
        "outputId": "b7b95935-d485-4fe5-dfbf-aa56e395b560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 50, 128)           256000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 128)               24704     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 280833 (1.07 MB)\n",
            "Trainable params: 280833 (1.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set batch size and number of epochs you want\n",
        "batch_size = 32\n",
        "epochs = 5\n",
        "\n",
        "model2.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhgjuo8W2d_1",
        "outputId": "4675aa4f-4aaf-4cf6-d145-10c86a83e56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "782/782 [==============================] - 39s 46ms/step - loss: 0.5585 - accuracy: 0.6973 - val_loss: 0.4772 - val_accuracy: 0.7798\n",
            "Epoch 2/5\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.4206 - accuracy: 0.8095 - val_loss: 0.4870 - val_accuracy: 0.7636\n",
            "Epoch 3/5\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 0.3385 - accuracy: 0.8557 - val_loss: 0.5110 - val_accuracy: 0.7754\n",
            "Epoch 4/5\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.2432 - accuracy: 0.9016 - val_loss: 0.6084 - val_accuracy: 0.7694\n",
            "Epoch 5/5\n",
            "782/782 [==============================] - 31s 40ms/step - loss: 0.1542 - accuracy: 0.9413 - val_loss: 0.7787 - val_accuracy: 0.7372\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cb40e852e60>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "\n",
        "loss, accuracy = model2.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQNn09aD3X5O",
        "outputId": "2e2bc81a-6834-4b44-8d88-ab6d8501c7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 0.7787 - accuracy: 0.7372\n",
            "Test accuracy: 0.7371600270271301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**"
      ],
      "metadata": {
        "id": "U2WwqfGgDm2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load the IMDB dataset\n",
        "max_features = 10000  # number of words to consider as features\n",
        "maxlen = 500  # maximum length of the review\n",
        "batch_size = 64\n",
        "\n",
        "# Load data from IMDB, already preprocessed as integer sequences\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure they have the same length (maxlen)\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer to map word indices to word embeddings\n",
        "model.add(Embedding(input_dim=max_features, output_dim=128))\n",
        "\n",
        "# LSTM layer\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "# Fully connected layer to produce final prediction\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Build the model by providing a batch input shape (required to resolve the issue)\n",
        "model.build(input_shape=(None, maxlen))  # explicitly build the model\n",
        "\n",
        "# Display model summary to verify the total parameters\n",
        "model.summary()\n",
        "\n",
        "# Early stopping callback to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=batch_size,\n",
        "                    validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "score, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "\n",
        "print(f\"Test score: {score}\")\n",
        "print(f\"Test accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "xbqMQc5DDmPV",
        "outputId": "c1e35446-4d7e-473d-e53a-0b548c7839ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,411,713\u001b[0m (5.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411,713</span> (5.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,411,713\u001b[0m (5.39 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411,713</span> (5.39 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m716s\u001b[0m 2s/step - accuracy: 0.6836 - loss: 0.5712 - val_accuracy: 0.8407 - val_loss: 0.3713\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 2s/step - accuracy: 0.8589 - loss: 0.3459 - val_accuracy: 0.7698 - val_loss: 0.4775\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m729s\u001b[0m 2s/step - accuracy: 0.8724 - loss: 0.3125 - val_accuracy: 0.8447 - val_loss: 0.3783\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m706s\u001b[0m 2s/step - accuracy: 0.9028 - loss: 0.2461 - val_accuracy: 0.8496 - val_loss: 0.3632\n",
            "Epoch 5/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9182 - loss: 0.2161 - val_accuracy: 0.8523 - val_loss: 0.4272\n",
            "Epoch 6/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m741s\u001b[0m 2s/step - accuracy: 0.9324 - loss: 0.1836 - val_accuracy: 0.8467 - val_loss: 0.3989\n",
            "Epoch 7/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m740s\u001b[0m 2s/step - accuracy: 0.9505 - loss: 0.1397 - val_accuracy: 0.8420 - val_loss: 0.4375\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 264ms/step - accuracy: 0.8400 - loss: 0.4424\n",
            "Test score: 0.43754124641418457\n",
            "Test accuracy: 0.8420000076293945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BI-LSTM**"
      ],
      "metadata": {
        "id": "CgOU-5RQcd6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load a simple text dataset or use your own dataset\n",
        "text_data = \"\"\"This is an example sentence for word prediction.\n",
        "               The machine learns to predict the next word in a sentence.\n",
        "               BiLSTM can capture the dependencies between words.\n",
        "               Word prediction is important in natural language processing.\"\"\"\n",
        "\n",
        "# Preprocess the data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text_data])\n",
        "sequences = tokenizer.texts_to_sequences([text_data])[0]\n",
        "\n",
        "# Prepare input and output sequences\n",
        "sequence_length = 5  # Lookback for previous words\n",
        "input_sequences = []\n",
        "output_words = []\n",
        "\n",
        "# Create input sequences (x) and output words (y)\n",
        "for i in range(sequence_length, len(sequences)):\n",
        "    input_sequences.append(sequences[i-sequence_length:i])  # last `sequence_length` words\n",
        "    output_words.append(sequences[i])  # the word to predict\n",
        "\n",
        "# Pad the input sequences to ensure they are all of the same length\n",
        "X = np.array(input_sequences)\n",
        "y = np.array(output_words)\n",
        "\n",
        "# The output labels need to be one-hot encoded\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(tokenizer.word_index)+1)\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 100\n",
        "hidden_units = 128\n",
        "\n",
        "# Build the BiLSTM model for next word prediction\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=embedding_dim, input_length=sequence_length))\n",
        "model.add(Bidirectional(LSTM(hidden_units)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(tokenizer.word_index)+1, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=50, batch_size=32)\n",
        "\n",
        "# Save the model\n",
        "model.save('next_word_prediction_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA4agKBPcbk7",
        "outputId": "e2520255-c6e5-472f-8a25-5b526836e482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 3.2966\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.1034 - loss: 3.2884\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.1724 - loss: 3.2817\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2414 - loss: 3.2741\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2759 - loss: 3.2659\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2759 - loss: 3.2591\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.2414 - loss: 3.2465\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.2414 - loss: 3.2400\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2414 - loss: 3.2314\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2759 - loss: 3.2185\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.2414 - loss: 3.2096\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2069 - loss: 3.2007\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2069 - loss: 3.1847\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2069 - loss: 3.1751\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.2069 - loss: 3.1577\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2069 - loss: 3.1458\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2414 - loss: 3.1190\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1724 - loss: 3.1045\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2069 - loss: 3.0773\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2069 - loss: 3.0538\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2414 - loss: 3.0213\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2069 - loss: 2.9939\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2069 - loss: 2.9626\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1724 - loss: 2.9190\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2069 - loss: 2.8660\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.1724 - loss: 2.8189\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.2069 - loss: 2.7818\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2069 - loss: 2.7204\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.1724 - loss: 2.6717\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2069 - loss: 2.5888\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2069 - loss: 2.5227\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.1724 - loss: 2.4444\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2069 - loss: 2.3799\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2069 - loss: 2.3140\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2414 - loss: 2.2057\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.2069 - loss: 2.1609\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.3793 - loss: 2.0743\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4138 - loss: 1.9961\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.4828 - loss: 1.9126\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5172 - loss: 1.7934\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.6207 - loss: 1.7291\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.6207 - loss: 1.6243\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6207 - loss: 1.5131\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5517 - loss: 1.4297\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6552 - loss: 1.3443\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6552 - loss: 1.2576\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7586 - loss: 1.1315\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7586 - loss: 1.1145\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7241 - loss: 1.0075\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8966 - loss: 0.9402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict the next word based on input sequence\n",
        "def predict_next_word(model, tokenizer, text, sequence_length=5):\n",
        "    # Tokenize the input text\n",
        "    sequence = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "    # Ensure that the input sequence is the correct length\n",
        "    sequence = sequence[-sequence_length:]\n",
        "\n",
        "    # Pad the sequence to make it the correct length for input\n",
        "    sequence = pad_sequences([sequence], maxlen=sequence_length)\n",
        "\n",
        "    # Predict the next word\n",
        "    pred = model.predict(sequence, verbose=0)\n",
        "\n",
        "    # Get the index of the predicted word\n",
        "    predicted_index = np.argmax(pred)\n",
        "\n",
        "    # Get the word corresponding to the predicted index\n",
        "    predicted_word = tokenizer.index_word.get(predicted_index, '')\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example: Predict the next word for a given sequence\n",
        "input_text = \"BiLSTM can capture\"\n",
        "predicted_word = predict_next_word(model, tokenizer, input_text)\n",
        "print(f\"Predicted next word: {predicted_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmtRWoogcwXa",
        "outputId": "30631516-ecc3-4970-c7a5-108d17fb775d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted next word: dependencies\n"
          ]
        }
      ]
    }
  ]
}